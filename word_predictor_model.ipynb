{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 19, 100)           277900    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2779)              419629    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 848129 (3.24 MB)\n",
      "Trainable params: 848129 (3.24 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "404/404 [==============================] - 20s 45ms/step - loss: 6.4382 - accuracy: 0.0495\n",
      "Epoch 2/10\n",
      "404/404 [==============================] - 23s 56ms/step - loss: 5.9801 - accuracy: 0.0635\n",
      "Epoch 3/10\n",
      "404/404 [==============================] - 24s 59ms/step - loss: 5.7765 - accuracy: 0.0691\n",
      "Epoch 4/10\n",
      "404/404 [==============================] - 25s 61ms/step - loss: 5.5837 - accuracy: 0.0821\n",
      "Epoch 5/10\n",
      "404/404 [==============================] - 25s 63ms/step - loss: 5.3815 - accuracy: 0.0935\n",
      "Epoch 6/10\n",
      "404/404 [==============================] - 24s 59ms/step - loss: 5.1783 - accuracy: 0.1097\n",
      "Epoch 7/10\n",
      "404/404 [==============================] - 24s 60ms/step - loss: 4.9758 - accuracy: 0.1220\n",
      "Epoch 8/10\n",
      "404/404 [==============================] - 26s 63ms/step - loss: 4.7831 - accuracy: 0.1336\n",
      "Epoch 9/10\n",
      "404/404 [==============================] - 26s 63ms/step - loss: 4.5877 - accuracy: 0.1482\n",
      "Epoch 10/10\n",
      "404/404 [==============================] - 24s 60ms/step - loss: 4.3950 - accuracy: 0.1632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1bf9c569a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import regex as re\n",
    "\n",
    "# Load the text data from a file\n",
    "with open(\"data2.txt\", \"r\", encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    " \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "input_sequences = []\n",
    "for sentence in data.split('\\n'):\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1, len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i + 1])\n",
    "\n",
    "max_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "padded_input_sequence = pad_sequences(input_sequences, maxlen=max_len, padding='pre')\n",
    "\n",
    "x = padded_input_sequence[:, :-1]\n",
    "y = padded_input_sequence[:, -1]\n",
    "\n",
    "# One-hot encode the labels\n",
    "y = to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(tokenizer.word_index) + 1, 100, input_length=max_len - 1))\n",
    "model.add(LSTM(150))\n",
    "# Make sure the number of units in the Dense layer matches the vocabulary size\n",
    "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
    "\n",
    "# Use 'sparse_categorical_crossentropy' for single integer labels\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(x, y, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 578ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def predict_words():\n",
    "    input_word = input_word_entry.get()\n",
    "    num_predictions = 3\n",
    "    text = input_word\n",
    "\n",
    "    for i in range(num_predictions):\n",
    "        token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "        padded_token_text = pad_sequences([token_text], maxlen=max_len - 1, padding=\"pre\")\n",
    "        predictions_for_input = model.predict(padded_token_text)\n",
    "        top_index = predictions_for_input.argsort()[0][-i - 1]\n",
    "\n",
    "        prediction_word = \"\"\n",
    "        for word, word_index in tokenizer.word_index.items():\n",
    "            if word_index == top_index:\n",
    "                prediction_word = word\n",
    "                break\n",
    "\n",
    "        if prediction_word:\n",
    "            prediction_labels[i].config(text=prediction_word, fg='black')  # Set text color to green\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Word Prediction\")\n",
    "root.configure(bg='lightblue')  \n",
    "\n",
    "# Create input widgets with improved styling\n",
    "input_word_label = tk.Label(root, text=\"Input Word:\", font=(\"Palatino\", 24, \"bold\"), fg=\"blue\")\n",
    "input_word_label.pack()\n",
    "input_word_entry = tk.Entry(root, font=(\"Palatino\", 22), bg=\"lightgray\", width=60,)\n",
    "input_word_entry.pack()\n",
    "\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=predict_words, font=(\"Palatino\", 18, \"bold\"), bg='black', fg='white')\n",
    "predict_button.pack()\n",
    "\n",
    "# Create Labels for displaying predictions with custom styles\n",
    "prediction_labels = []\n",
    "for i in range(3):\n",
    "    label = tk.Label(root, text=\"\", font=(\"Palatino\", 24, \"italic\"), fg='darkblue')\n",
    "    label.pack()\n",
    "    prediction_labels.append(label)\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
